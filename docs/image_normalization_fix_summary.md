# å›¾åƒå½’ä¸€åŒ–é—®é¢˜ä¿®å¤æ€»ç»“

## ğŸ› é—®é¢˜æè¿°

åœ¨ `runs/diffusion_A_2cam_3/xyz_viz/` æ–‡ä»¶å¤¹ä¸‹çš„å¯è§†åŒ–å›¾åƒå‡ºç°ï¼š
- **è¿‡æ›** (over-exposure)
- **åè‰²** (color shiftï¼Œåè“è‰²)
- **å¯¹æ¯”åº¦å¼‚å¸¸**

## ğŸ” é—®é¢˜è¯Šæ–­

### 1. è¿è¡Œè¯Šæ–­è„šæœ¬

```bash
conda activate rev2fwd_il
python scripts/debug_image_normalization.py runs/diffusion_A_2cam_3/checkpoints/checkpoints/last/pretrained_model
```

### 2. å‘ç°çš„é—®é¢˜

**é…ç½®æ–‡ä»¶** (`config.json`):
```json
"normalization_mapping": {
    "VISUAL": "MEAN_STD",  // â† ä½¿ç”¨äº† ImageNet å½’ä¸€åŒ–ï¼
    "STATE": "MIN_MAX",
    "ACTION": "MIN_MAX"
}
```

**ImageNet å½’ä¸€åŒ–å‚æ•°**:
- mean (RGB): `[0.485, 0.456, 0.406]`
- std (RGB): `[0.229, 0.224, 0.225]`

**å¯è§†åŒ–ä»£ç é—®é¢˜**:
```python
# é”™è¯¯çš„ä»£ç  (æ—§ç‰ˆæœ¬)
img_np = processed_batch["observation.image"][0, -1]  # å·²ç» ImageNet å½’ä¸€åŒ–
img_np = (img_np * 255).astype(np.uint8)  # âŒ ç›´æ¥ * 255ï¼Œæ²¡æœ‰åå½’ä¸€åŒ–
```

### 3. é—®é¢˜å½±å“

å¯¹äº mid-gray åƒç´  (0.5, 0.5, 0.5):

| æ­¥éª¤ | R | G | B | è¯´æ˜ |
|------|---|---|---|------|
| åŸå§‹å€¼ | 0.500 | 0.500 | 0.500 | ä¸­ç°è‰² |
| ImageNet å½’ä¸€åŒ–å | 0.066 | 0.196 | 0.418 | (img - mean) / std |
| **é”™è¯¯å¯è§†åŒ–** | **16** | **50** | **106** | âŒ ç›´æ¥ * 255 |
| **æ­£ç¡®å¯è§†åŒ–** | **127** | **127** | **127** | âœ… åå½’ä¸€åŒ–å * 255 |

é”™è¯¯å¯è§†åŒ–å¯¼è‡´ï¼š
- æ•´ä½“åæš—ï¼ˆ16, 50, 106 vs 127, 127, 127ï¼‰
- åè“è‰²ï¼ˆB=106 >> R=16ï¼‰
- å¯¹æ¯”åº¦å¤±çœŸ

## âœ… ä¿®å¤æ–¹æ¡ˆ

### ä¿®å¤ä½ç½® 1: è®­ç»ƒå¯è§†åŒ–ä»£ç 

**æ–‡ä»¶**: `src/rev2fwd_il/train/lerobot_train_with_viz.py`

**ä¿®å¤å†…å®¹**: åœ¨ 4 ä¸ªä½ç½®æ·»åŠ åå½’ä¸€åŒ–
1. `extract_xyz_visualization_data()` - table camera
2. `extract_xyz_visualization_data()` - wrist camera  
3. `extract_action_chunk_data()` - table camera
4. `extract_action_chunk_data()` - wrist camera

**ä¿®å¤ä»£ç **:
```python
# IMPORTANT: Reverse ImageNet normalization before visualization
# Images are normalized with: (img - mean) / std
# We need to reverse: img = normalized * std + mean
imagenet_mean = np.array([0.485, 0.456, 0.406]).reshape(3, 1, 1)
imagenet_std = np.array([0.229, 0.224, 0.225]).reshape(3, 1, 1)
img_np = img_np * imagenet_std + imagenet_mean  # Reverse normalization

# Then convert to uint8
img_np = np.transpose(img_np, (1, 2, 0))  # CHW -> HWC
img_np = (img_np * 255).clip(0, 255).astype(np.uint8)
```

### ä¿®å¤ä½ç½® 2: æ¨ç†ä»£ç  (Debug è¾“å‡º)

**æ–‡ä»¶**: `scripts/41_test_A_diffusion_visualize.py`

**ä¿®å¤å†…å®¹**: æ·»åŠ  debug è¾“å‡ºéªŒè¯å½’ä¸€åŒ–

```python
# DEBUG: Print image stats before/after preprocessing
if t == 0:
    print(f"[DEBUG] Step 0: Image BEFORE preprocessing:")
    print(f"  Range: [{table_rgb_chw.min():.4f}, {table_rgb_chw.max():.4f}]")
    print(f"  Mean per channel: R={...}, G={...}, B={...}")
    
    # After preprocessing
    print(f"[DEBUG] Step 0: After preprocessing (ImageNet normalized):")
    print(f"  Range: [{policy_inputs['observation.image'].min():.4f}, ...]")
    print(f"  Expected after ImageNet norm: mean~0, std~1 per channel")
```

## ğŸ§ª éªŒè¯ä¿®å¤

### è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
conda activate rev2fwd_il
python scripts/test_image_normalization_fix.py
```

### æµ‹è¯•ç»“æœ

```
================================================================================
Testing ImageNet Normalization Fix
================================================================================

1. Original image (mid-gray):
   Mean per channel: R=0.5000, G=0.5000, B=0.5000

2. After ImageNet normalization:
   Mean per channel: R=0.0655, G=0.1964, B=0.4178

3. OLD (WRONG) visualization (normalized * 255):
   Mean per channel: R=16.0, G=50.0, B=106.0
   âš ï¸  This gives wrong colors! (should be ~127 for mid-gray)

4. NEW (CORRECT) visualization (reverse norm, then * 255):
   Mean per channel: R=127.0, G=127.0, B=127.0
   âœ“ Correct! Mid-gray should be ~127

5. Verification:
   âœ“ PASS: Visualization is correct!
================================================================================
```

### å¯è§†åŒ–å¯¹æ¯”

æµ‹è¯•è„šæœ¬ç”Ÿæˆäº†å¯¹æ¯”å›¾: `docs/image_normalization_comparison.png`

æ˜¾ç¤ºäº†ï¼š
- åŸå§‹å›¾åƒ (Ground Truth)
- é”™è¯¯å¯è§†åŒ– (OLD - åè“è‰²ã€è¿‡æš—)
- æ­£ç¡®å¯è§†åŒ– (NEW - ä¸åŸå§‹ä¸€è‡´)

## ğŸ“‹ åç»­æ­¥éª¤

### 1. é‡æ–°ç”Ÿæˆè®­ç»ƒå¯è§†åŒ–

```bash
# ä½¿ç”¨ä¿®å¤åçš„ä»£ç é‡æ–°è®­ç»ƒï¼ˆç”Ÿæˆæ­£ç¡®çš„å¯è§†åŒ–ï¼‰
CUDA_VISIBLE_DEVICES=1 python scripts/31_train_A_diffusion.py \
    --dataset data/A_forward_with_2images.npz \
    --out runs/diffusion_A_2cam_test \
    --steps 200 \
    --enable_xyz_viz
```

æ£€æŸ¥ `runs/diffusion_A_2cam_test/xyz_viz/` ä¸­çš„å›¾åƒæ˜¯å¦æ­£å¸¸ã€‚

### 2. éªŒè¯æ¨ç†æ—¶çš„å½’ä¸€åŒ–

```bash
# è¿è¡Œæ¨ç†å¹¶æŸ¥çœ‹ debug è¾“å‡º
CUDA_VISIBLE_DEVICES=1 python scripts/41_test_A_diffusion_visualize.py \
    --checkpoint runs/diffusion_A_2cam_3/checkpoints/checkpoints/last/pretrained_model \
    --out_dir runs/diffusion_A_2cam_3/videos_test \
    --num_episodes 1
```

æ£€æŸ¥ debug è¾“å‡ºï¼Œç¡®è®¤ï¼š
- å›¾åƒåœ¨ preprocessing å‰: [0, 1]
- å›¾åƒåœ¨ preprocessing å: mean~0, std~1 (ImageNet å½’ä¸€åŒ–)

### 3. å¯¹æ¯”æ–°æ—§å¯è§†åŒ–

```bash
# å¯¹æ¯”ä¿®å¤å‰åçš„å¯è§†åŒ–
ls runs/diffusion_A_2cam_3/xyz_viz/          # æ—§çš„ï¼ˆæœ‰é—®é¢˜ï¼‰
ls runs/diffusion_A_2cam_test/xyz_viz/       # æ–°çš„ï¼ˆä¿®å¤åï¼‰
```

## ğŸ“Š æŠ€æœ¯ç»†èŠ‚

### ImageNet å½’ä¸€åŒ–å…¬å¼

**å‰å‘ (è®­ç»ƒ/æ¨ç†)**:
```python
normalized = (img - mean) / std
```

**åå‘ (å¯è§†åŒ–)**:
```python
img = normalized * std + mean
```

### å®Œæ•´çš„å¯è§†åŒ–æµç¨‹

```python
# 1. ä» processed_batch è·å–å›¾åƒ (å·² ImageNet å½’ä¸€åŒ–)
img_np = processed_batch["observation.image"][0, -1].cpu().numpy()  # (C, H, W)

# 2. åå½’ä¸€åŒ–åˆ° [0, 1]
imagenet_mean = np.array([0.485, 0.456, 0.406]).reshape(3, 1, 1)
imagenet_std = np.array([0.229, 0.224, 0.225]).reshape(3, 1, 1)
img_np = img_np * imagenet_std + imagenet_mean  # (C, H, W) [0, 1]

# 3. è½¬æ¢æ ¼å¼å¹¶ç¼©æ”¾åˆ° [0, 255]
img_np = np.transpose(img_np, (1, 2, 0))  # (H, W, C)
img_np = (img_np * 255).clip(0, 255).astype(np.uint8)  # uint8 [0, 255]
```

## ğŸ¯ å…³é”®è¦ç‚¹

1. **LeRobot é»˜è®¤å¯¹å›¾åƒä½¿ç”¨ ImageNet å½’ä¸€åŒ–**
   - è¿™æ˜¯ä¸ºäº†é…åˆé¢„è®­ç»ƒçš„ Vision Backbone (ResNet18)
   - å½’ä¸€åŒ–æ¨¡å¼åœ¨ `config.json` ä¸­å®šä¹‰

2. **å¯è§†åŒ–æ—¶å¿…é¡»åå½’ä¸€åŒ–**
   - ä» `processed_batch` æå–çš„å›¾åƒå·²ç»å½’ä¸€åŒ–
   - å¿…é¡»å…ˆåå½’ä¸€åŒ–å†è½¬æ¢ä¸º uint8

3. **è®­ç»ƒå’Œæ¨ç†çš„å½’ä¸€åŒ–å¿…é¡»ä¸€è‡´**
   - ä¸¤è€…éƒ½ä½¿ç”¨ç›¸åŒçš„ ImageNet mean/std
   - Preprocessor è‡ªåŠ¨å¤„ç†ï¼Œæ— éœ€æ‰‹åŠ¨å¹²é¢„

4. **ä¿®å¤ä¸å½±å“æ¨¡å‹æ€§èƒ½**
   - åªä¿®å¤äº†å¯è§†åŒ–ä»£ç 
   - è®­ç»ƒå’Œæ¨ç†çš„æ•°æ®æµç¨‹æ²¡æœ‰æ”¹å˜
   - æ¨¡å‹çœ‹åˆ°çš„æ•°æ®ä»ç„¶æ˜¯æ­£ç¡®çš„

## ğŸ“š ç›¸å…³æ–‡ä»¶

- **è¯Šæ–­è„šæœ¬**: `scripts/debug_image_normalization.py`
- **æµ‹è¯•è„šæœ¬**: `scripts/test_image_normalization_fix.py`
- **ä¿®å¤ä»£ç **: `src/rev2fwd_il/train/lerobot_train_with_viz.py`
- **æ¨ç†ä»£ç **: `scripts/41_test_A_diffusion_visualize.py`
- **è¯¦ç»†åˆ†æ**: `docs/image_normalization_analysis.md`
- **å¯¹æ¯”å›¾**: `docs/image_normalization_comparison.png`

## âœ¨ æ€»ç»“

é—®é¢˜å·²æˆåŠŸä¿®å¤ï¼å¯è§†åŒ–å›¾åƒç°åœ¨åº”è¯¥æ˜¾ç¤ºæ­£ç¡®çš„é¢œè‰²å’Œäº®åº¦ï¼Œä¸å†æœ‰è¿‡æ›å’Œåè‰²é—®é¢˜ã€‚ä¿®å¤åªå½±å“å¯è§†åŒ–ä»£ç ï¼Œä¸å½±å“æ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„æ­£ç¡®æ€§ã€‚
