Metadata-Version: 2.4
Name: rev2fwd-il
Version: 0.0.0
Summary: Minimal Isaac Lab runner / Reverse-to-Forward IL utilities
Author: rev2fwd-il
License: MIT
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.26
Provides-Extra: extras
Requires-Dist: pyyaml; extra == "extras"
Requires-Dist: tqdm; extra == "extras"
Requires-Dist: h5py; extra == "extras"
Requires-Dist: matplotlib; extra == "extras"
Requires-Dist: rich; extra == "extras"
Requires-Dist: imageio; extra == "extras"
Requires-Dist: imageio-ffmpeg; extra == "extras"
Requires-Dist: tensorboard; extra == "extras"
Requires-Dist: einops; extra == "extras"
Requires-Dist: wandb; extra == "extras"
Provides-Extra: train
Requires-Dist: torch; extra == "train"
Requires-Dist: torchvision; extra == "train"
Provides-Extra: dev
Requires-Dist: ruff; extra == "dev"
Requires-Dist: mypy; extra == "dev"

# rev2fwd-il: Reverse-to-Forward Imitation Learning (Isaac Lab)

> Core idea: Run an easy reverse policy B (goal → table), collect reverse trajectories,
> then time-reverse them to generate forward data for training policy A (table → goal).

---

## 1. Installation

```bash
conda create -n rev2fwd_il python=3.11
conda activate rev2fwd_il
pip install -U torch==2.7.0 torchvision==0.22.0 --index-url https://download.pytorch.org/whl/cu128
pip install isaaclab[isaacsim,all]==2.3.0 --extra-index-url https://pypi.nvidia.com
pip install wandb==0.24.0 
pip install lerobot==0.4.2
pip install numpy==1.26.0
pip install -e ./isaaclab_tasks
pip install -e .
```

---

## 2. Workflow

The complete pipeline consists of 5 scripts:

| Script | Description | Input | Output |
|--------|-------------|-------|--------|
| `1_collect_data.py` | Collect reverse trajectory data | - | `data/B_*.npz` |
| `2_inspect_data.py` | Visualize and inspect data | NPZ file | PNG/MP4/JSON |
| `3_make_forward_data.py` | Time-reverse to generate forward data | `data/B_*.npz` | `data/A_*.npz` |
| `4_train_diffusion.py` | Train Diffusion Policy | `data/A_*.npz` | `runs/*/checkpoints` |
| `5_eval_diffusion.py` | Evaluate and visualize | checkpoint | `runs/*/videos` |

---

## 3. Usage Examples

### Step 1: Collect Reverse Trajectory Data

```bash
CUDA_VISIBLE_DEVICES=0 python scripts/1_collect_data.py \
    --headless --num_episodes 500 --num_envs 256 \
    --out data/B_2images_goal.npz
```

### Step 2: Visualize and Inspect Data

```bash
python scripts/2_inspect_data.py \
    --dataset data/B_2images_goal.npz \
    --episode 0 --enable_xyz_viz
```

### Step 3: Generate Forward Training Data

```bash
python scripts/3_make_forward_data.py \
    --input data/B_2images_goal.npz \
    --out data/A_2images_goal.npz
```

### Step 4: Train Diffusion Policy

```bash
# Single GPU training
CUDA_VISIBLE_DEVICES=0 python scripts/4_train_diffusion.py \
    --dataset data/A_2images_goal.npz \
    --out runs/diffusion_A_goal \
    --batch_size 64 --steps 50000 \
    --include_obj_pose --wandb

# Multi-GPU training
CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --nproc_per_node=4 \
    scripts/4_train_diffusion.py \
    --dataset data/A_2images_goal.npz \
    --out runs/diffusion_A_goal \
    --batch_size 64 --steps 50000 \
    --include_obj_pose --wandb
```

### Step 5: Evaluate and Visualize

```bash
CUDA_VISIBLE_DEVICES=0 python scripts/5_eval_diffusion.py \
    --checkpoint runs/diffusion_A_goal/checkpoints/checkpoints/last/pretrained_model \
    --out_dir runs/diffusion_A_goal/videos \
    --num_episodes 5 --visualize_xyz --headless
```

---

## 4. Data Format

### Reverse Data (B_*.npz)

```
obs:           (T, 36)      State observations
images:        (T, H, W, 3) Table camera RGB images
wrist_images:  (T, H, W, 3) Wrist camera RGB images
ee_pose:       (T, 7)       End-effector pose [x,y,z,qw,qx,qy,qz]
obj_pose:      (T, 7)       Object pose
action:        (T, 8)       Goal action [ee_pose, gripper]
gripper:       (T,)         Gripper action (+1=open, -1=close)
fsm_state:     (T,)         FSM state
```

### Forward Data (A_*.npz)

Same format, but trajectory direction is reversed (from random table position to goal).

---

## 5. Archived Scripts

Legacy scripts have been moved to `scripts_archive/`, including:
- MLP BC training/evaluation
- Early data collection scripts
- Debug utilities
