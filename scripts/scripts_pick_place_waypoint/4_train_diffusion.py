#!/usr/bin/env python3
"""Step 4: Train Diffusion Policy using LeRobot.

This script trains a vision-based Diffusion Policy on the forward trajectory
data generated by script 3.

=============================================================================
INPUT DATA FORMAT (from script 3_make_forward_data.py)
=============================================================================
NPZ file with episodes list, each dict containing:
    - obs:           (T, 36)  State observations
    - images:        (T, H, W, 3)  RGB images from table camera (uint8)
    - wrist_images:  (T, H, W, 3)  RGB images from wrist camera (uint8)
    - ee_pose:       (T, 7)   EE poses [x, y, z, qw, qx, qy, qz]
    - obj_pose:      (T, 7)   Object poses
    - action:        (T, 8)   Goal actions [ee_pose, gripper]

=============================================================================
TMUX BACKGROUND EXECUTION (Recommended for long training)
=============================================================================
# Create a new tmux session and run training in background
tmux new -s train -d 'CUDA_VISIBLE_DEVICES=0 python scripts/4_train_diffusion.py --dataset data/A_pick_place.npz --out runs/diffusion_A_pick_place --steps 50000 --wandb'

# Common tmux commands:
#   tmux ls                  # List all sessions
#   tmux a -t train          # Attach to session named "train"
#   tmux kill-session -t train  # Kill session named "train"
#   Ctrl+b d                 # Detach from current session (inside tmux)
#   Ctrl+b [                 # Enter scroll mode (q to exit)

=============================================================================
USAGE EXAMPLES
=============================================================================
# Single GPU training
CUDA_VISIBLE_DEVICES=0 python scripts/4_train_diffusion.py \
    --dataset data/A_2images_goal.npz \
    --out runs/diffusion_A_goal \
    --batch_size 64 --steps 50000 \
    --include_obj_pose --wandb

# Multi-GPU training
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 torchrun --nproc_per_node=8 \
    scripts/4_train_diffusion.py \
    --dataset data/A_pick_place.npz \
    --out runs/diffusion_A_pick_place \
    --batch_size 64 --steps 50000 \
    --include_obj_pose --wandb

# Data conversion only (for debugging)
CUDA_VISIBLE_DEVICES=1 python scripts/4_train_diffusion.py \
    --dataset data/A_pick_place.npz \
    --out runs/diffusion_A_pick_place \
    --convert_only --include_obj_pose

=============================================================================
"""

from __future__ import annotations

import argparse
import json
import os
import shutil
import time
from pathlib import Path

import numpy as np
import torch

# Suppress verbose output from video encoders (SVT-AV1, FFmpeg, etc.)
os.environ["AV_LOG_LEVEL"] = "quiet"
os.environ["SVT_LOG"] = "0"  # Suppress SVT-AV1 encoder logs
os.environ["FFMPEG_LOG_LEVEL"] = "quiet"


def _parse_args() -> argparse.Namespace:
    """Parse command-line arguments."""
    parser = argparse.ArgumentParser(
        description="Train Policy B with Diffusion Policy using goal-based actions.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    # =========================================================================
    # Input/Output Arguments
    # =========================================================================
    parser.add_argument(
        "--dataset",
        type=str,
        default="data/B_goal_actions_latest.npz",
        help="Path to the goal-action dataset NPZ file from script 14.",
    )
    parser.add_argument(
        "--out",
        type=str,
        default="runs/diffusion_B_goal",
        help="Output directory for saving model checkpoints and logs.",
    )
    parser.add_argument(
        "--lerobot_dataset_dir",
        type=str,
        default=None,
        help="Directory to save the converted LeRobot dataset. "
             "If not specified, uses {out}/lerobot_dataset.",
    )

    # =========================================================================
    # Mode Selection
    # =========================================================================
    parser.add_argument(
        "--convert_only",
        action="store_true",
        help="Only convert data to LeRobot format, don't train.",
    )
    parser.add_argument(
        "--skip_convert",
        action="store_true",
        help="Skip data conversion (assume already converted).",
    )
    parser.add_argument(
        "--force_convert",
        action="store_true",
        help="Force re-conversion even if dataset exists.",
    )
    parser.add_argument(
        "--include_obj_pose",
        action="store_true",
        help="Include object pose (7D) in observation.state. "
             "If enabled, state becomes 14D (ee_pose + obj_pose).",
    )

    # =========================================================================
    # Training Hyperparameters
    # =========================================================================
    parser.add_argument(
        "--num_episodes",
        type=int,
        default=-1,
        help="Number of episodes to use for training. Default: -1 (use all episodes).",
    )
    parser.add_argument(
        "--steps",
        type=int,
        default=100000,
        help="Number of training steps. Default: 100000.",
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=32,
        help="Mini-batch size for training. Default: 32.",
    )
    parser.add_argument(
        "--lr",
        type=float,
        default=1e-4,
        help="Learning rate for Adam optimizer. Default: 1e-4.",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=0,
        help="Random seed for reproducibility. Default: 0.",
    )
    parser.add_argument(
        "--num_workers",
        type=int,
        default=4,
        help="Number of dataloader workers. Default: 4.",
    )
    parser.add_argument(
        "--fps",
        type=int,
        default=20,
        help="Frames per second of the dataset. Default: 20.",
    )

    # =========================================================================
    # Diffusion Policy Architecture
    # =========================================================================
    parser.add_argument(
        "--n_obs_steps",
        type=int,
        default=2,
        help="Number of observation steps. Default: 2.",
    )
    parser.add_argument(
        "--horizon",
        type=int,
        default=16,
        help="Diffusion horizon (action sequence length). Default: 16.",
    )
    parser.add_argument(
        "--n_action_steps",
        type=int,
        default=8,
        help="Number of action steps to execute. Default: 8.",
    )
    parser.add_argument(
        "--vision_backbone",
        type=str,
        default="resnet18",
        help="Vision backbone architecture. Default: resnet18.",
    )
    parser.add_argument(
        "--crop_shape",
        type=int,
        nargs=2,
        default=[128, 128],
        help="Image crop shape (H, W). Default: 128 128.",
    )
    parser.add_argument(
        "--num_train_timesteps",
        type=int,
        default=100,
        help="Number of diffusion timesteps. Default: 100.",
    )
    parser.add_argument(
        "--pretrained_backbone_weights",
        type=str,
        default=None,
        help="Pretrained weights for vision backbone (e.g., 'ResNet18_Weights.IMAGENET1K_V1'). Default: None.",
    )

    # =========================================================================
    # Logging and Checkpointing
    # =========================================================================
    parser.add_argument(
        "--log_freq",
        type=int,
        default=50,
        help="Log metrics every N steps. Default: 50.",
    )
    parser.add_argument(
        "--save_freq",
        type=int,
        default=20000,
        help="Save checkpoint every N steps. Default: 20000.",
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        help="Resume training from the latest checkpoint.",
    )
    parser.add_argument(
        "--overwrite",
        action=argparse.BooleanOptionalAction,
        default=True,
        help="Overwrite existing checkpoints directory if it exists. Default: True. Use --no-overwrite to disable.",
    )
    parser.add_argument(
        "--viz_save_freq",
        type=int,
        default=20000,
        help="Save checkpoint and XYZ visualization every N steps. Default: 20000.",
    )
    parser.add_argument(
        "--enable_xyz_viz",
        action="store_true",
        help="Enable XYZ curve visualization during training.",
    )

    # =========================================================================
    # Overfit Mode
    # =========================================================================
    parser.add_argument(
        "--overfit",
        action="store_true",
        help="Enable overfit mode: use only 1 episode and save initial env params "
             "for reproducible testing. Automatically sets num_episodes=1.",
    )

    # =========================================================================
    # Device Selection
    # =========================================================================
    parser.add_argument(
        "--device",
        type=str,
        default=None,
        help="Torch device ('cuda' or 'cpu'). Auto-detect if not specified.",
    )

    # =========================================================================
    # WandB Logging
    # =========================================================================
    parser.add_argument(
        "--wandb",
        action="store_true",
        help="Enable Weights & Biases logging.",
    )
    parser.add_argument(
        "--wandb_project",
        type=str,
        default="rev2fwd-diffusion-pick-place-A",
        help="WandB project name. Default: rev2fwd-diffusion-pick-place-A.",
    )

    # =========================================================================
    # Validation Set
    # =========================================================================
    parser.add_argument(
        "--val_split",
        type=float,
        default=0.0,
        help="Fraction of episodes to use for validation (0.0 to 1.0). Default: 0.0 (no validation).",
    )
    parser.add_argument(
        "--val_freq",
        type=int,
        default=500,
        help="Compute validation loss every N steps. Default: 500.",
    )

    return parser.parse_args()


def load_episodes_from_npz(path: str, num_episodes: int = -1) -> list[dict]:
    """Load episodes from NPZ file created by script 14.
    
    Args:
        path: Path to the NPZ file.
        num_episodes: Number of episodes to load. -1 means load all.
        
    Returns:
        List of episode dictionaries.
    """
    path = Path(path)
    print(f"Loading NPZ file: {path} ...")
    load_start = time.time()
    with np.load(path, allow_pickle=True) as data:
        episodes = list(data["episodes"])
    load_time = time.time() - load_start
    total_episodes = len(episodes)
    
    # Limit number of episodes if specified
    if num_episodes > 0:
        episodes = episodes[:num_episodes]
        print(f"Loaded {len(episodes)}/{total_episodes} episodes from {path} "
              f"(limited by --num_episodes) in {load_time:.1f}s")
    else:
        print(f"Loaded {len(episodes)} episodes from {path} in {load_time:.1f}s")
    
    # Verify that the dataset has 'action' field (from script 14)
    if len(episodes) > 0 and "action" not in episodes[0]:
        raise ValueError(
            f"Dataset does not contain 'action' field. "
            f"Please use data collected by script 14 (14_collect_B_with_goal_actions.py). "
            f"Available fields: {list(episodes[0].keys())}"
        )
    
    return episodes


def convert_npz_to_lerobot_format(
    npz_path: str,
    output_dir: str,
    fps: int = 20,
    repo_id: str = "local/rev2fwd_diffusion_B",
    force: bool = False,
    num_episodes: int = -1,
    include_obj_pose: bool = False,
    overfit: bool = False,
) -> tuple[int, int, bool, dict | None]:
    """Convert NPZ dataset (with goal actions) to LeRobot v3.0 format.
    
    The key difference from script 31's conversion is that we use the 'action'
    field directly from the NPZ file, which contains the FSM goal positions,
    instead of computing actions from consecutive ee_poses.
    
    Args:
        npz_path: Path to input NPZ file.
        output_dir: Directory to save LeRobot dataset.
        fps: Frames per second (should match data collection).
        repo_id: Repository ID for the dataset.
        force: Force re-conversion even if dataset exists.
        num_episodes: Number of episodes to use. -1 means use all.
        include_obj_pose: Whether to include object pose in observation.state.
        overfit: Whether to extract overfit env init params from first episode.
        
    Returns:
        Tuple of (image_height, image_width, has_wrist_camera, overfit_env_init).
        overfit_env_init is None if overfit=False, otherwise a dict with initial poses.
    """
    # Suppress verbose logging from video encoding libraries
    import logging
    logging.getLogger("imageio_ffmpeg").setLevel(logging.ERROR)
    logging.getLogger("av").setLevel(logging.ERROR)
    
    from lerobot.datasets.lerobot_dataset import LeRobotDataset
    
    output_dir = Path(output_dir)
    
    # Check if dataset already exists BEFORE loading NPZ
    if output_dir.exists() and not force:
        print(f"LeRobot dataset already exists at {output_dir}")
        print("Skipping NPZ loading and conversion. Use --force_convert to re-convert.")
        # Read metadata from existing dataset
        meta_path = output_dir / "meta" / "info.json"
        if meta_path.exists():
            with open(meta_path, "r") as f:
                info = json.load(f)
            # Extract image shape from features
            features = info.get("features", {})
            if "observation.image" in features:
                img_shape = features["observation.image"]["shape"]  # (C, H, W)
                image_height, image_width = img_shape[1], img_shape[2]
            else:
                # Fallback: try to read from video files
                image_height, image_width = 128, 128  # default
            has_wrist = "observation.wrist_image" in features
            print(f"  Loaded metadata: image=({image_height}, {image_width}), has_wrist={has_wrist}")
            
            # Try to load overfit_env_init from existing JSON file first
            overfit_env_init = None
            if overfit:
                # Check if overfit_env_init.json exists in parent directory (out_dir)
                out_dir_parent = output_dir.parent
                overfit_init_path = out_dir_parent / "overfit_env_init.json"
                if overfit_init_path.exists():
                    with open(overfit_init_path, "r") as f:
                        overfit_env_init = json.load(f)
                    print(f"  Overfit mode: loaded from {overfit_init_path}")
                    print(f"    initial_obj_pose={overfit_env_init['initial_obj_pose'][:3]}")
                else:
                    # Fallback: load NPZ to get overfit params
                    print(f"  Overfit mode: {overfit_init_path} not found, loading from NPZ...")
                    episodes = load_episodes_from_npz(npz_path, num_episodes=1)
                    ep0 = episodes[0]
                    overfit_env_init = {
                        "initial_obj_pose": ep0["obj_pose"][0].tolist(),
                        "initial_ee_pose": ep0["ee_pose"][0].tolist(),
                        "place_pose": ep0.get("place_pose", [0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]),
                        "goal_pose": ep0.get("goal_pose", [0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]),
                    }
                    if isinstance(overfit_env_init["place_pose"], np.ndarray):
                        overfit_env_init["place_pose"] = overfit_env_init["place_pose"].tolist()
                    if isinstance(overfit_env_init["goal_pose"], np.ndarray):
                        overfit_env_init["goal_pose"] = overfit_env_init["goal_pose"].tolist()
                    print(f"  Overfit mode: extracted initial obj_pose={overfit_env_init['initial_obj_pose'][:3]}")
            
            return image_height, image_width, has_wrist, overfit_env_init
        else:
            print("  Warning: meta/info.json not found, loading NPZ to get metadata...")
    
    # Load episodes (only if we need to convert or get metadata)
    episodes = load_episodes_from_npz(npz_path, num_episodes=num_episodes)
    image_shape = episodes[0]["images"].shape[1:]  # (H, W, 3)
    has_wrist = "wrist_images" in episodes[0]
    
    # Extract overfit env init params if requested
    overfit_env_init = None
    if overfit and len(episodes) > 0:
        ep0 = episodes[0]
        overfit_env_init = {
            "initial_obj_pose": ep0["obj_pose"][0].tolist(),
            "initial_ee_pose": ep0["ee_pose"][0].tolist(),
            "place_pose": ep0.get("place_pose", [0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]),
            "goal_pose": ep0.get("goal_pose", [0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]),
        }
        if isinstance(overfit_env_init["place_pose"], np.ndarray):
            overfit_env_init["place_pose"] = overfit_env_init["place_pose"].tolist()
        if isinstance(overfit_env_init["goal_pose"], np.ndarray):
            overfit_env_init["goal_pose"] = overfit_env_init["goal_pose"].tolist()
        print(f"\n[Overfit Mode] Extracted initial env params:")
        print(f"  initial_obj_pose: {overfit_env_init['initial_obj_pose']}")
        print(f"  initial_ee_pose: {overfit_env_init['initial_ee_pose']}")
    
    # If dataset exists and we already loaded NPZ just for metadata, return early
    if output_dir.exists() and not force:
        return image_shape[0], image_shape[1], has_wrist, overfit_env_init
    
    # Remove existing dataset if force conversion
    if output_dir.exists() and force:
        print(f"Removing existing dataset at {output_dir}")
        shutil.rmtree(output_dir)
    
    print(f"\n{'='*60}")
    print("Converting NPZ to LeRobot format (Goal-Action Version)")
    print(f"{'='*60}")
    print(f"  Input: {npz_path}")
    print(f"  Output: {output_dir}")
    print(f"  FPS: {fps}")
    print(f"  Action type: Next frame ee_pose + gripper (from 'action' field)")
    
    if len(episodes) == 0:
        raise ValueError("No episodes found in NPZ file!")
    
    # Get data dimensions from first episode
    ep0 = episodes[0]
    if include_obj_pose:
        state_dim = 15  # ee_pose (7) + obj_pose (7) + gripper (1)
        state_names = [
            "ee_x", "ee_y", "ee_z", "ee_qw", "ee_qx", "ee_qy", "ee_qz",
            "obj_x", "obj_y", "obj_z", "obj_qw", "obj_qx", "obj_qy", "obj_qz",
            "gripper",
        ]
    else:
        state_dim = 8  # ee_pose (7) + gripper (1)
        state_names = ["ee_x", "ee_y", "ee_z", "ee_qw", "ee_qx", "ee_qy", "ee_qz", "gripper"]
    action_dim = 8  # next ee_pose + gripper: [x, y, z, qw, qx, qy, qz, gripper]
    
    print(f"  Table camera image shape: {image_shape} (H, W, C)")
    if has_wrist:
        wrist_shape = ep0["wrist_images"].shape[1:]
        print(f"  Wrist camera image shape: {wrist_shape} (H, W, C)")
    else:
        print(f"  Wrist camera: not available")
    print(f"  State dim: {state_dim} (ee_pose + gripper{' + obj_pose' if include_obj_pose else ''})")
    print(f"  Action dim: {action_dim} (next ee_pose + gripper)")
    
    # Print FSM state distribution for first episode
    if "fsm_state" in ep0:
        from rev2fwd_il.experts.pickplace_expert_b import ExpertState
        fsm_states = ep0["fsm_state"]
        print(f"  FSM state distribution (episode 0):")
        for state in ExpertState:
            count = (fsm_states == state.value).sum()
            if count > 0:
                print(f"      {state.name}: {count} steps")
    
    print(f"{'='*60}\n")
    
    # Define features for LeRobot dataset
    features = {
        "observation.image": {
            "dtype": "video",
            "shape": (3, image_shape[0], image_shape[1]),  # (C, H, W)
            "names": ["channel", "height", "width"],
        },
        "observation.state": {
            "dtype": "float32",
            "shape": (state_dim,),
            "names": state_names,
        },
        "action": {
            "dtype": "float32",
            "shape": (action_dim,),
            "names": ["next_ee_x", "next_ee_y", "next_ee_z", "next_ee_qw", "next_ee_qx", "next_ee_qy", "next_ee_qz", "gripper"],
        },
    }
    
    # Add wrist camera feature if available
    if has_wrist:
        wrist_shape = ep0["wrist_images"].shape[1:]
        features["observation.wrist_image"] = {
            "dtype": "video",
            "shape": (3, wrist_shape[0], wrist_shape[1]),  # (C, H, W)
            "names": ["channel", "height", "width"],
        }
    
    # Create LeRobot dataset
    dataset = LeRobotDataset.create(
        repo_id=repo_id,
        fps=fps,
        features=features,
        root=output_dir,
        robot_type="franka",
        use_videos=True,
        image_writer_threads=4,
    )
    
    # Process each episode
    total_frames = 0
    start_time = time.time()
    num_episodes_total = len(episodes)
    
    # Determine print frequency based on dataset size
    print_freq = max(1, num_episodes_total // 20)  # Print ~20 times during conversion
    
    print(f"\nProcessing {num_episodes_total} episodes...")
    
    for ep_idx, ep in enumerate(episodes):
        T = len(ep["images"])
        
        # Print progress at start of each episode (or at intervals for large datasets)
        if num_episodes_total <= 50 or (ep_idx + 1) % print_freq == 0 or ep_idx == 0:
            elapsed = time.time() - start_time
            rate = (ep_idx / elapsed) if elapsed > 0 and ep_idx > 0 else 0
            eta = (num_episodes_total - ep_idx) / rate if rate > 0 else 0
            print(f"  [{ep_idx + 1}/{num_episodes_total}] Processing episode {ep_idx}, "
                  f"{T} frames | {rate:.1f} ep/s | ETA: {eta:.0f}s")
        
        # Extract data
        images = ep["images"]  # (T, H, W, 3) uint8
        ee_pose = ep["ee_pose"]  # (T, 7)
        obj_pose = ep["obj_pose"]  # (T, 7)
        actions = ep["action"]  # (T, 8) - GOAL ACTIONS from script 14
        wrist_images = ep.get("wrist_images", None)  # (T, H, W, 3) uint8 or None
        
        # =====================================================================
        # Action format: next frame's ee_pose + current gripper
        # =====================================================================
        # action[t] = [ee_pose[t+1], gripper[t]] - where robot should move next
        # Get gripper states from the gripper field in episode
        gripper_states = ep.get("gripper", actions[:, 7])  # Use gripper field or fall back to action's gripper
        
        for t in range(T):
            # Current observation
            img = images[t]  # (H, W, 3)
            # Current gripper state (from previous action or initial state)
            gripper_state = np.array([gripper_states[t]], dtype=np.float32)  # (1,)
            if include_obj_pose:
                state = np.concatenate([ee_pose[t], obj_pose[t], gripper_state])  # (15,)
            else:
                state = np.concatenate([ee_pose[t], gripper_state])  # (8,)
            
            # Action: next frame's ee_pose + current gripper
            action = actions[t]  # (8,) [next_ee_x, next_ee_y, next_ee_z, next_ee_qw, next_ee_qx, next_ee_qy, next_ee_qz, gripper]
            
            frame = {
                "observation.image": img,  # Will be converted to video
                "observation.state": state.astype(np.float32),
                "action": action.astype(np.float32),
                "task": "reverse_pick_and_place",
            }
            
            # Add wrist camera image if available
            if wrist_images is not None:
                frame["observation.wrist_image"] = wrist_images[t]
            
            dataset.add_frame(frame)
        
        # Save episode
        dataset.save_episode()
        total_frames += T
    
    # Finalize dataset
    print("\nFinalizing dataset (encoding videos)...")
    dataset.finalize()
    
    elapsed = time.time() - start_time
    print(f"\n{'='*60}")
    print("Conversion Complete!")
    print(f"{'='*60}")
    print(f"  Total episodes: {len(episodes)}")
    print(f"  Total frames: {total_frames}")
    print(f"  Has wrist camera: {has_wrist}")
    print(f"  Action type: FSM goal position")
    print(f"  Time: {elapsed:.1f}s")
    print(f"  Dataset saved to: {output_dir}")
    if overfit_env_init is not None:
        print(f"  Overfit mode: initial_obj_pose={overfit_env_init['initial_obj_pose'][:3]}")
    print(f"{'='*60}\n")
    
    return image_shape[0], image_shape[1], has_wrist, overfit_env_init


def train_with_lerobot_api(
    args: argparse.Namespace,
    lerobot_dataset_dir: Path,
    image_height: int,
    image_width: int,
    has_wrist: bool = False,
    include_obj_pose: bool = False,
    overfit_env_init: dict | None = None,
    train_episodes: list[int] | None = None,
    val_episodes: list[int] | None = None,
) -> dict:
    """Train using LeRobot's Python API.
    
    Args:
        args: Parsed command-line arguments.
        lerobot_dataset_dir: Path to LeRobot dataset.
        image_height: Image height.
        image_width: Image width.
        has_wrist: Whether the dataset has wrist camera images.
        include_obj_pose: Whether object pose is included in observation.state.
        overfit_env_init: Optional dict with initial env params for overfit mode.
        train_episodes: List of episode indices for training (None = all).
        val_episodes: List of episode indices for validation (None = no validation).
        
    Returns:
        Dictionary with training results.
    """
    from lerobot.configs.default import DatasetConfig, WandBConfig
    from lerobot.configs.train import TrainPipelineConfig
    from lerobot.policies.diffusion.configuration_diffusion import DiffusionConfig
    from lerobot.configs.types import FeatureType, PolicyFeature
    from lerobot.scripts.lerobot_train import train
    from rev2fwd_il.train.lerobot_train_with_viz import train_with_xyz_visualization
    
    out_dir = Path(args.out)
    out_dir.mkdir(parents=True, exist_ok=True)
    
    # Check if running in distributed mode
    is_main_process = True
    if "LOCAL_RANK" in os.environ:
        local_rank = int(os.environ["LOCAL_RANK"])
        is_main_process = (local_rank == 0)
    
    # Handle overwrite: remove existing checkpoints directory (only on main process)
    checkpoint_dir = out_dir / "checkpoints"
    if is_main_process and args.overwrite and checkpoint_dir.exists() and not args.resume:
        print(f"Removing existing checkpoints directory: {checkpoint_dir}")
        shutil.rmtree(checkpoint_dir)
    
    # Save overfit_env_init.json to out_dir (NOT checkpoints)
    if is_main_process and args.overfit and overfit_env_init is not None:
        overfit_init_path = out_dir / "overfit_env_init.json"
        with open(overfit_init_path, "w") as f:
            json.dump(overfit_env_init, f, indent=2)
        print(f"[Overfit Mode] Saved env init params to: {overfit_init_path}")
    
    # Sync all processes before continuing
    if torch.distributed.is_initialized():
        torch.distributed.barrier()
    
    # Device selection
    device = args.device
    if device is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # Determine state dimension based on whether obj_pose is included
    # Now includes gripper state: ee_pose(7) + gripper(1) [+ obj_pose(7)]
    state_dim = 15 if include_obj_pose else 8
    
    # Configure input/output features for the policy
    input_features = {
        "observation.image": PolicyFeature(
            type=FeatureType.VISUAL,
            shape=(3, image_height, image_width),
        ),
        "observation.state": PolicyFeature(
            type=FeatureType.STATE,
            shape=(state_dim,),
        ),
    }
    
    # Add wrist camera feature if available
    if has_wrist:
        input_features["observation.wrist_image"] = PolicyFeature(
            type=FeatureType.VISUAL,
            shape=(3, image_height, image_width),
        )
    
    output_features = {
        "action": PolicyFeature(
            type=FeatureType.ACTION,
            shape=(8,),
        ),
    }
    
    # Create Diffusion Policy configuration
    policy_cfg = DiffusionConfig(
        n_obs_steps=args.n_obs_steps,
        horizon=args.horizon,
        n_action_steps=args.n_action_steps,
        input_features=input_features,
        output_features=output_features,
        vision_backbone=args.vision_backbone,
        crop_shape=tuple(args.crop_shape),
        num_train_timesteps=args.num_train_timesteps,
        pretrained_backbone_weights=args.pretrained_backbone_weights,
        device=device,
        push_to_hub=False,
        optimizer_lr=args.lr,
    )
    
    # =========================================================================
    # DEBUG: Print normalization settings for training
    # =========================================================================
    print("\n" + "=" * 60)
    print("[DEBUG] TRAINING Normalization Settings")
    print("=" * 60)
    print(f"  policy_cfg.normalization_mapping:")
    for feat_type, norm_mode in policy_cfg.normalization_mapping.items():
        print(f"    {feat_type}: {norm_mode}")
    print("=" * 60 + "\n")
    
    # Create dataset configuration (with train episodes if specified)
    dataset_cfg = DatasetConfig(
        repo_id="local/rev2fwd_diffusion_B",
        root=str(lerobot_dataset_dir),
        episodes=train_episodes,
    )
    
    # Create validation dataset configuration if val_episodes provided
    val_dataset_cfg = None
    if val_episodes is not None and len(val_episodes) > 0:
        val_dataset_cfg = DatasetConfig(
            repo_id="local/rev2fwd_diffusion_B",
            root=str(lerobot_dataset_dir),
            episodes=val_episodes,
        )
    
    # Create WandB configuration
    wandb_cfg = WandBConfig(
        enable=args.wandb,
        project=args.wandb_project,
    )
    
    # Create training pipeline configuration
    checkpoint_dir = out_dir / "checkpoints"
    
    # When resuming, load the config from checkpoint and update necessary fields
    resume_config_path = None  # Track for sys.argv injection
    if args.resume:
        checkpoints_subdir = checkpoint_dir / "checkpoints"
        if not checkpoints_subdir.exists():
            raise FileNotFoundError(
                f"Cannot resume: checkpoint directory {checkpoints_subdir} does not exist. "
                f"Please run training without --resume first."
            )
        checkpoint_dirs = sorted([d for d in checkpoints_subdir.iterdir() if d.is_dir()])
        if not checkpoint_dirs:
            raise FileNotFoundError(
                f"Cannot resume: no checkpoints found in {checkpoints_subdir}. "
                f"Please run training without --resume first."
            )
        latest_checkpoint = checkpoint_dirs[-1]
        print(f"Resuming from checkpoint: {latest_checkpoint}")
        
        # LeRobot requires loading config from checkpoint when resuming
        resume_config_path = latest_checkpoint / "pretrained_model" / "train_config.json"
        if not resume_config_path.exists():
            raise FileNotFoundError(
                f"Cannot resume: train_config.json not found at {resume_config_path}. "
                f"Please run training without --resume first."
            )
        print(f"Loading config from: {resume_config_path}")
        
        # Load the saved config from checkpoint
        train_cfg = TrainPipelineConfig.from_pretrained(str(resume_config_path.parent))
        
        # Update fields that should change on resume
        train_cfg.resume = True
        train_cfg.steps = args.steps  # Allow extending training steps
        train_cfg.wandb = wandb_cfg  # Update wandb config
        train_cfg.checkpoint_path = latest_checkpoint
        train_cfg.policy.pretrained_path = latest_checkpoint / "pretrained_model"
        
        print(f"  Loaded config, will continue training to {args.steps} steps")
    else:
        train_cfg = TrainPipelineConfig(
            dataset=dataset_cfg,
            policy=policy_cfg,
            output_dir=checkpoint_dir,
            seed=args.seed,
            num_workers=args.num_workers,
            batch_size=args.batch_size,
            steps=args.steps,
            log_freq=args.log_freq,
            save_freq=args.save_freq,
            save_checkpoint=True,
            wandb=wandb_cfg,
            resume=False,
            eval_freq=0,
        )
    
    # Print training info
    print("\n" + "=" * 60)
    print("Starting Diffusion Policy Training (Task B - Goal Actions)")
    print("=" * 60)
    print(f"  Dataset: {args.dataset}")
    print(f"  LeRobot dataset: {lerobot_dataset_dir}")
    print(f"  Output: {checkpoint_dir}")
    print(f"  Steps: {args.steps}")
    print(f"  Batch size: {args.batch_size}")
    print(f"  Learning rate: {args.lr}")
    print(f"  Image shape: ({image_height}, {image_width})")
    print(f"  Has wrist camera: {has_wrist}")
    print(f"  Include obj_pose: {include_obj_pose}")
    print(f"  State dim: {state_dim}")
    print(f"  Crop shape: {tuple(args.crop_shape)}")
    print(f"  Horizon: {args.horizon}")
    print(f"  N obs steps: {args.n_obs_steps}")
    print(f"  N action steps: {args.n_action_steps}")
    print(f"  Vision backbone: {args.vision_backbone}")
    print(f"  Device: {device}")
    print(f"  WandB: {args.wandb}")
    print(f"  XYZ visualization: {args.enable_xyz_viz}")
    print(f"  Viz save frequency: {args.viz_save_freq} steps")
    print(f"  Action type: FSM goal position (sharp)")
    if train_episodes is not None:
        print(f"  Train episodes: {len(train_episodes)}")
    if val_episodes is not None:
        print(f"  Val episodes: {len(val_episodes)}")
        print(f"  Val frequency: {args.val_freq} steps")
    print("=" * 60 + "\n")
    
    # Run training with or without XYZ visualization
    # Note: When resuming, we need to inject config_path into sys.argv for LeRobot's
    # parser.parse_arg() to find it during validate()
    import sys
    original_argv = sys.argv.copy()
    if resume_config_path is not None:
        sys.argv = [sys.argv[0], f"--config_path={resume_config_path}"]
    
    try:
        if args.enable_xyz_viz:
            xyz_viz_dir = out_dir / "xyz_viz"
            train_with_xyz_visualization(
                train_cfg,
                viz_save_freq=args.viz_save_freq,
                xyz_viz_dir=xyz_viz_dir,
                val_dataset_cfg=val_dataset_cfg,
                val_freq=args.val_freq,
            )
        else:
            train(train_cfg)
    finally:
        sys.argv = original_argv
    
    return {
        "output_dir": str(checkpoint_dir),
        "steps": args.steps,
    }


def main() -> None:
    """Main entry point."""
    args = _parse_args()
    
    # Handle overfit mode: force num_episodes=1
    if args.overfit:
        if args.num_episodes != 1:
            print(f"\n[Overfit Mode] Setting num_episodes=1 (was {args.num_episodes})")
            args.num_episodes = 1
        out_dir_temp = Path(args.out)
        overfit_init_path = out_dir_temp / "overfit_env_init.json"
        lerobot_dataset_dir_temp = args.lerobot_dataset_dir
        if lerobot_dataset_dir_temp is None:
            lerobot_dataset_dir_temp = out_dir_temp / "lerobot_dataset"
        lerobot_dataset_dir_temp = Path(lerobot_dataset_dir_temp)
        
        if overfit_init_path.exists() and lerobot_dataset_dir_temp.exists():
            print(f"[Overfit Mode] Found existing overfit_env_init.json and dataset, skipping re-conversion")
        elif not args.force_convert:
            print("[Overfit Mode] Enabling force_convert to extract env init params")
            args.force_convert = True
    
    # Set random seed
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(args.seed)
    
    # Check if running in distributed mode
    local_rank = int(os.environ.get("LOCAL_RANK", 0))
    world_size = int(os.environ.get("WORLD_SIZE", 1))
    is_main_process = (local_rank == 0)
    
    # Initialize distributed process group if needed
    if world_size > 1 and not torch.distributed.is_initialized():
        torch.distributed.init_process_group(backend="nccl")
    
    # Setup paths
    out_dir = Path(args.out)
    out_dir.mkdir(parents=True, exist_ok=True)
    
    lerobot_dataset_dir = args.lerobot_dataset_dir
    if lerobot_dataset_dir is None:
        lerobot_dataset_dir = out_dir / "lerobot_dataset"
    lerobot_dataset_dir = Path(lerobot_dataset_dir)
    
    # Variable to store overfit env init params
    overfit_env_init = None
    
    # Step 1: Convert data to LeRobot format (only on main process)
    if not args.skip_convert:
        if is_main_process:
            image_height, image_width, has_wrist, overfit_env_init = convert_npz_to_lerobot_format(
                npz_path=args.dataset,
                output_dir=lerobot_dataset_dir,
                fps=args.fps,
                repo_id="local/rev2fwd_diffusion_B",
                force=args.force_convert,
                num_episodes=args.num_episodes,
                include_obj_pose=args.include_obj_pose,
                overfit=args.overfit,
            )
            # Write metadata to a temp file so other processes can read it
            meta_file = out_dir / ".conversion_meta.json"
            meta_data = {
                "image_height": image_height,
                "image_width": image_width,
                "has_wrist": has_wrist,
                "include_obj_pose": args.include_obj_pose,
                "overfit_env_init": overfit_env_init,
            }
            with open(meta_file, "w") as f:
                json.dump(meta_data, f, indent=2)
            
            # Save overfit_env_init.json
            if args.overfit and overfit_env_init is not None:
                overfit_init_path = out_dir / "overfit_env_init.json"
                with open(overfit_init_path, "w") as f:
                    json.dump(overfit_env_init, f, indent=2)
                print(f"\n[Overfit Mode] Saved env init params to: {overfit_init_path}")
        
        # Synchronize all processes
        if torch.distributed.is_initialized():
            torch.distributed.barrier()
        
        # Non-main processes read metadata from file
        if not is_main_process:
            meta_file = out_dir / ".conversion_meta.json"
            with open(meta_file, "r") as f:
                meta = json.load(f)
            image_height = meta["image_height"]
            image_width = meta["image_width"]
            has_wrist = meta["has_wrist"]
            overfit_env_init = meta.get("overfit_env_init", None)
    else:
        # Load episodes to get image shape and check for wrist camera
        episodes = load_episodes_from_npz(args.dataset, num_episodes=args.num_episodes)
        image_shape = episodes[0]["images"].shape[1:]  # (H, W, 3)
        image_height, image_width = image_shape[0], image_shape[1]
        has_wrist = "wrist_images" in episodes[0]
        
        # Extract overfit env init params if in overfit mode
        if args.overfit and len(episodes) > 0:
            ep0 = episodes[0]
            overfit_env_init = {
                "initial_obj_pose": ep0["obj_pose"][0].tolist(),
                "initial_ee_pose": ep0["ee_pose"][0].tolist(),
                "place_pose": ep0.get("place_pose", [0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]),
                "goal_pose": ep0.get("goal_pose", [0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]),
            }
            if isinstance(overfit_env_init["place_pose"], np.ndarray):
                overfit_env_init["place_pose"] = overfit_env_init["place_pose"].tolist()
            if isinstance(overfit_env_init["goal_pose"], np.ndarray):
                overfit_env_init["goal_pose"] = overfit_env_init["goal_pose"].tolist()
            
            overfit_init_path = out_dir / "overfit_env_init.json"
            with open(overfit_init_path, "w") as f:
                json.dump(overfit_env_init, f, indent=2)
            print(f"\n[Overfit Mode] Saved env init params to: {overfit_init_path}")
    
    if args.convert_only:
        if is_main_process:
            print("Data conversion complete. Exiting (--convert_only flag).")
        return
    
    # Compute train/val episode split
    train_episodes = None
    val_episodes = None
    
    if args.val_split > 0.0:
        meta_path = lerobot_dataset_dir / "meta" / "info.json"
        if meta_path.exists():
            with open(meta_path, "r") as f:
                info = json.load(f)
            total_episodes = info.get("total_episodes", 0)
        else:
            episodes_dir = lerobot_dataset_dir / "data"
            if episodes_dir.exists():
                total_episodes = len(list(episodes_dir.glob("episode_*")))
            else:
                total_episodes = 0
        
        if total_episodes > 0:
            all_episode_indices = list(range(total_episodes))
            rng = np.random.default_rng(args.seed)
            rng.shuffle(all_episode_indices)
            
            n_val = max(1, int(total_episodes * args.val_split))
            val_episodes = sorted(all_episode_indices[:n_val])
            train_episodes = sorted(all_episode_indices[n_val:])
            
            if is_main_process:
                print(f"\n{'='*60}")
                print("Train/Val Split")
                print(f"{'='*60}")
                print(f"  Total episodes: {total_episodes}")
                print(f"  Val split: {args.val_split:.1%}")
                print(f"  Train episodes: {len(train_episodes)}")
                print(f"  Val episodes: {len(val_episodes)}")
                print(f"{'='*60}\n")
        else:
            if is_main_process:
                print(f"Warning: Could not determine total episodes, skipping validation split")
    
    # Step 2: Train the policy
    result = train_with_lerobot_api(
        args=args,
        lerobot_dataset_dir=lerobot_dataset_dir,
        image_height=image_height,
        image_width=image_width,
        has_wrist=has_wrist,
        include_obj_pose=args.include_obj_pose,
        overfit_env_init=overfit_env_init,
        train_episodes=train_episodes,
        val_episodes=val_episodes,
    )
    
    print("\n" + "=" * 60)
    print("Training Complete!")
    print("=" * 60)
    print(f"  Output directory: {result['output_dir']}")
    print(f"  Total steps: {result['steps']}")
    print(f"  Action type: FSM goal position (sharp)")
    print("=" * 60)


if __name__ == "__main__":
    main()
